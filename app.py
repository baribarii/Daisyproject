import os
from flask import Flask, request, jsonify
import threading # ìŠ¤í¬ë˜í•‘ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëŒë¦¬ê¸° ìœ„í•œ ì„ì‹œë°©í¸
import asyncio
# BlogScraper.py íŒŒì¼ ì•ˆì— ìˆëŠ” main í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
# ë§Œì•½ BlogScraper.pyì˜ main í•¨ìˆ˜ ì´ë¦„ì´ ë‹¤ë¥´ë‹¤ë©´ ë°”ê¿”ì£¼ì„¸ìš”.
try:
    # BlogScraper.pyì˜ main í•¨ìˆ˜ë¥¼ ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ ì¶©ëŒ ë°©ì§€
    from BlogScraper import main as run_scraper_main
except ImportError:
    print("ì˜¤ë¥˜: BlogScraper.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ main í•¨ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    # ì‹¤ì œ main í•¨ìˆ˜ê°€ ì—†ë‹¤ë©´, ì•„ë˜ run_scraper_main í˜¸ì¶œ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
    def run_scraper_main():
        print("ìŠ¤í¬ë˜í¼ main í•¨ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {"error": "ìŠ¤í¬ë˜í¼ í•¨ìˆ˜ ì—†ìŒ"}


app = Flask(__name__)

# ìŠ¤í¬ë˜í•‘ ìƒíƒœë¥¼ ê°„ë‹¨íˆ ì €ì¥ (ì„œë²„ ì¬ì‹œì‘í•˜ë©´ ì´ˆê¸°í™”ë¨ - ì„ì‹œë°©í¸)
scrape_status = "idle" # ìƒíƒœ: idle, running, completed, error
scrape_result_data = None

# ìŠ¤í¬ë˜í•‘ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜
def run_scrape_task():
    global scrape_status, scrape_result_data
    print("ë°±ê·¸ë¼ìš´ë“œ ìŠ¤í¬ë˜í•‘ ì‘ì—… ì‹œì‘...")
    scrape_status = "running"
    scrape_result_data = None # ì´ì „ ê²°ê³¼ ì´ˆê¸°í™”
    try:
        # ìƒˆ asyncio ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ìŠ¤í¬ë˜í¼ ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        # run_scraper_main() í•¨ìˆ˜ê°€ ìŠ¤í¬ë© ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
        result = loop.run_until_complete(run_scraper_main())
        loop.close()

        scrape_result_data = result # ê²°ê³¼ ì €ì¥
        scrape_status = "completed"
        print("ìŠ¤í¬ë˜í•‘ ì‘ì—… ì™„ë£Œ.")

        # TODO: ì—¬ê¸°ì„œ ì™„ë£Œëœ ê²°ê³¼ë¥¼ Replitìœ¼ë¡œ ë³´ë‚´ëŠ” ì½”ë“œ ì¶”ê°€ í•„ìš” (requests ì‚¬ìš©)
        # ì˜ˆ: requests.post(os.environ.get("REPLIT_CALLBACK_URL"), json=result)

    except Exception as e:
        print(f"ìŠ¤í¬ë˜í•‘ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        scrape_status = "error"
        scrape_result_data = {"error": str(e)}

# app.py íŒŒì¼ì— ì¶”ê°€í•  ë‚´ìš©
@app.route('/') # ë£¨íŠ¸ ì£¼ì†Œ ('/')ë¡œ GET ìš”ì²­ì´ ì˜¤ë©´
def home():
    # ê°„ë‹¨í•œ í™˜ì˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•´ìš”.
    return "ì•ˆë…•í•˜ì„¸ìš”! ë°ì´ì§€ ìŠ¤í¬ë˜í¼ ì„œë²„ê°€ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤. ğŸ˜Š"

# ì™¸ë¶€(Replit)ì—ì„œ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•˜ë¼ê³  ìš”ì²­í•˜ëŠ” ì£¼ì†Œ
@app.route('/scrape', methods=['POST'])
def start_scraping():
    global scrape_status
    if scrape_status == "running":
        return jsonify({"message": "ì´ë¯¸ ìŠ¤í¬ë˜í•‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤."}), 409 # Conflict

    # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤í¬ë˜í•‘ ì‹œì‘
    # threadingì€ ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì´ì§€ë§Œ, ìš”ì²­ì´ ë§ì•„ì§€ë©´ ë¬¸ì œë  ìˆ˜ ìˆìŒ
    thread = threading.Thread(target=run_scrape_task)
    thread.start()

    return jsonify({"message": "ìŠ¤í¬ë˜í•‘ ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤."}), 202 # Accepted

# ìŠ¤í¬ë˜í•‘ ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” ì£¼ì†Œ
@app.route('/status', methods=['GET'])
def get_status():
    global scrape_status
    return jsonify({"status": scrape_status})

# ìŠ¤í¬ë˜í•‘ ê²°ê³¼ë¥¼ í™•ì¸í•˜ëŠ” ì£¼ì†Œ (ì™„ë£Œ í›„)
@app.route('/result', methods=['GET'])
def get_result():
    global scrape_status, scrape_result_data
    if scrape_status == "completed":
        return jsonify(scrape_result_data)
    elif scrape_status == "error":
        return jsonify(scrape_result_data), 500 # Internal Server Error (or other code)
    else:
        return jsonify({"message": "ìŠ¤í¬ë˜í•‘ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì‹œì‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 202 # Accepted (or 404 Not Found)

if __name__ == '__main__':
    # ì„œë²„ ì‹¤í–‰ (RailwayëŠ” ë³´í†µ 8080 í¬íŠ¸ë¥¼ ì¢‹ì•„í•´ìš”)
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port)